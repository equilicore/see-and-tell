# Captions Module
Given the captions generated by the image to text model, the faces detected by the face recognition model,
this module is responsible for generating the final personalized captions by:
1. extracting the piece of texts representing characters in the captions
2. mapping each detected character (face) to the most probable piece of text

## The Extraction step
1. Building the constituency tree of a given caption (sentence)
2. Recursively traversing the tree and extracting in each subtree the longest Noun Phrase satisfying the following heuristics:
    1. The noun Phrase must contain at most one 'Person' word   
    2. The word in question cannot be proceeded with a VERB or a NOUN

The semantic meaning of a word is inferred using wordnet provided by the NLTK library


## The Mapping step
This step is based on simple statistical ideas.
1. Given the extracted pieces of texts from each caption and the corresponding detected faces, I build 2 occurrence matrices:
    * a term-class matrix: calculating the number of times a term was present with a given class in the same (caption, class) pair
    * a class-term matrix: where each term is associated with the unique number of classes it appears with
    * definite term-class matrix: calculating the number of pairs (caption, class) where the term belongs to 'caption' and there is only one 'class' predicted / detected.

2. The calculations are conducted on all (captions, classes) to guarantee as much statistical significance as possible
3. Using the calculations, a customized version of tf-idf score can be assigned to a pair (term, class) and in a given caption, each class is assigned the piece of text maximizing that score.


